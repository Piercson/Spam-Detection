{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "median-supervision",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8e9f884d40be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "import helpers\n",
    "import figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-bulletin",
   "metadata": {},
   "source": [
    "Lets look at the data from Kaggle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-surgery",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"spam.csv\",encoding='latin-1')\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-humanity",
   "metadata": {},
   "source": [
    "All the columns are *object* data types, we have only text info in each of the columns.\n",
    "\n",
    "To check if there is any null values in the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-australian",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-alpha",
   "metadata": {},
   "source": [
    "*Unnamed: 2*, *Unnamed: 3*, and *Unnamed: 4* have large amount of null values (also the proportion of of null to non-null values are large)\n",
    "The desciption of the dataset does says that v1 is the classification and v2 is the message, so the other columns having a lot of null values makes sense. I would why it was included?\n",
    "\n",
    "Since columns v1 and v2 are the columns that will work the best, We can keep v1 and v2 because and rename them to help clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-turkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\"Unnamed: 2\",\"Unnamed: 3\",\"Unnamed: 4\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-wallet",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={\"v1\":\"class\",\"v2\":\"msg\"})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-message",
   "metadata": {},
   "source": [
    "Creating a word map of both Spam and Ham messages will help us visualise a difference between the two groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-strike",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = data[data['class'] == 'spam']\n",
    "ham = data[data['class'] == 'ham']\n",
    "\n",
    "spam_words = helpers.get_words(spam.msg)\n",
    "ham_words = helpers.get_words(ham.msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "figures.plot_wordclouds(spam_words,ham_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-month",
   "metadata": {},
   "source": [
    "Spam sms messages have words like \"txt, call, free, mobile,...\" and not spam words (called ham?) are \"will, u, now, go,...\"\n",
    "There are words that each of the sets have in common (\"u, now, call,..\") but hopefully there is a big difference bettween spam and ham messages that the model can tell the difference most of the time\n",
    "\n",
    "Lets start cleaning the data. The goal is to create the smallest set of unique words that will hopefully indenty if the sms message is spam or not. Punctuation and whitespaces will be remove because whitespaces will help us indicate the class and punctuation will be removed since \"Hello!!!\" is just \"Hello\" in meaning (although you could argue that punctuation could help classify the data we want the smallest set possible). Stopping words, which are commonly used words in the english language (They should appear frequently in both classes) will be removed along with any numbers.\n",
    "\n",
    "WWe will also try to get words to a root form by using stemming techniques such as PorterStemmer and WordNetLemmatizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-peace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-wallet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(col, technique):\n",
    "    stopwords = STOPWORDS\n",
    "    output = []\n",
    "    if technique == 'PorterStemmer':\n",
    "        tech = PorterStemmer()\n",
    "        get_root = tech.stem\n",
    "    else:\n",
    "        tech = WordNetLemmatizer()\n",
    "        get_root = tech.lemmatize\n",
    "    \n",
    "    tokens = col.split()\n",
    "    for token in tokens:\n",
    "        cleaned_token = token.lower()\n",
    "        if token in stopwords:\n",
    "            continue\n",
    "        cleaned_token = re.sub(r'[0-9]+', '', cleaned_token)\n",
    "        cleaned_token = re.sub(r'[^\\w\\s]', '', cleaned_token)\n",
    "        cleaned_token = re.sub(r'[_]', '', cleaned_token)\n",
    "        cleaned_token = get_root(cleaned_token)\n",
    "        output.append(cleaned_token)\n",
    "    output = list(filter(lambda x: x!='',output)) \n",
    "    return \" \".join(word for word in output)\n",
    "\n",
    "data['cleaned_stemm'] = data.msg.apply(clean_text,technique='PorterStemmer')\n",
    "data['cleaned_lemm'] = data.msg.apply(clean_text,technique='WordNetLemmatizer')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "experienced-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm\n",
    "\n",
    "import seaborn as sns\n",
    "vectorize = TfidfVectorizer()\n",
    "features = vectorize.fit(data['cleaned_stemm'])\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(data['cleaned_stemm'], data['class'],train_size=0.8, test_size=0.2,random_state=0)\n",
    "model = svm.SVC(kernel='poly')\n",
    "model.fit(vectorize.transform(X_train).toarray(),y_train)\n",
    "predictions = model.predict(vectorize.transform(X_valid).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "based-camcorder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9345291479820628\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf = confusion_matrix(y_valid,predictions,labels=[\"spam\",\"ham\"])\n",
    "labels = ['Spam',\"Ham\"]\n",
    "sns.heatmap(cf,cbar=False,xticklabels=labels,yticklabels=labels,annot=True,fmt=\"d\",cmap='Blues')\n",
    "print(model.score(vectorize.transform(X_valid).toarray(),y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "centered-eclipse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
